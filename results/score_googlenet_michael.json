{
  "job": "googlenet",
  "who": "michael",
  "infos": [
    {
      "taski": 0,
      "task": "Fairness",
      "dics": [
        {
          "todo": 0,
          "question": "Decisions made by the model are biased against certain groups or individuals",
          "O": 6.0,
          "S": 3.0,
          "D": 5.0
        }
      ],
      "score": 4.481404746557164,
      "ori_weight": 2.0,
      "weight": 0.35
    },
    {
      "taski": 1,
      "task": "Robustness",
      "dics": [
        {
          "todo": 2,
          "question": "Repeated model executions do not generate the same or similar outputs",
          "O": 10.0,
          "S": 5.0,
          "D": 10.0
        }
      ],
      "score": 10.0,
      "ori_weight": 0.0,
      "weight": 0.1
    },
    {
      "taski": 2,
      "task": "Integrity",
      "dics": [
        {
          "todo": 1,
          "question": "No output uncertainties are given",
          "O": 10.0,
          "S": 5.0,
          "D": 9.0
        }
      ],
      "score": 10.0,
      "ori_weight": 1.0,
      "weight": 0.225
    },
    {
      "taski": 3,
      "task": "Explainability",
      "dics": [
        {
          "todo": 0,
          "question": "The model\u2019s decision-making process is not transparent",
          "O": 2.0,
          "S": 6.0,
          "D": 9.0
        }
      ],
      "score": 4.762203155904598,
      "ori_weight": 1.0,
      "weight": 0.225
    },
    {
      "taski": 4,
      "task": "Safety",
      "dics": [
        {
          "todo": 2,
          "question": "Erroneous decisions might lead to critical consequences",
          "O": 8.0,
          "S": 5.0,
          "D": 8.0
        }
      ],
      "score": 6.839903786706787,
      "ori_weight": 0.0,
      "weight": 0.1
    }
  ],
  "result": 6.573977750044221
}