{
  "job": "googlenet",
  "who": "nair",
  "infos": [
    {
      "taski": 0,
      "task": "Fairness",
      "dics": [
        {
          "todo": 0,
          "question": "Decisions made by the model are biased against certain groups or individuals",
          "O": 3.0,
          "S": 3.0,
          "D": 8.0
        }
      ],
      "score": 4.160167646103808,
      "ori_weight": 5.0,
      "weight": 0.2
    },
    {
      "taski": 1,
      "task": "Robustness",
      "dics": [
        {
          "todo": 2,
          "question": "Repeated model executions do not generate the same or similar outputs",
          "O": 2.0,
          "S": 2.0,
          "D": 8.0
        }
      ],
      "score": 3.1748021039363987,
      "ori_weight": 5.0,
      "weight": 0.2
    },
    {
      "taski": 2,
      "task": "Integrity",
      "dics": [
        {
          "todo": 0,
          "question": "It cannot be guaranteed, that the model was not tampered with",
          "O": 6.0,
          "S": 6.0,
          "D": 8.0
        }
      ],
      "score": 6.603854497789253,
      "ori_weight": 5.0,
      "weight": 0.2
    },
    {
      "taski": 3,
      "task": "Explainability",
      "dics": [
        {
          "todo": 0,
          "question": "The model\u2019s decision-making process is not transparent",
          "O": 3.0,
          "S": 3.0,
          "D": 6.0
        }
      ],
      "score": 3.7797631496846193,
      "ori_weight": 5.0,
      "weight": 0.2
    },
    {
      "taski": 4,
      "task": "Safety",
      "dics": [
        {
          "todo": 2,
          "question": "Erroneous decisions might lead to critical consequences",
          "O": 6.0,
          "S": 6.0,
          "D": 8.0
        }
      ],
      "score": 6.603854497789253,
      "ori_weight": 5.0,
      "weight": 0.2
    }
  ],
  "result": 4.864488379060667
}