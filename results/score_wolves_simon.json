{
  "job": "wolves",
  "who": "simon",
  "infos": [
    {
      "taski": 0,
      "task": "Fairness",
      "dics": [
        {
          "todo": 0,
          "question": "Decisions made by the model are biased against certain groups or individuals",
          "O": 1.0,
          "S": 5.0,
          "D": 9.0
        }
      ],
      "score": 3.5568933044900626,
      "ori_weight": 30.0,
      "weight": 0.26666666666666666
    },
    {
      "taski": 1,
      "task": "Robustness",
      "dics": [
        {
          "todo": 1,
          "question": "The model does not generalize to different datasets",
          "O": 1.0,
          "S": 0.0,
          "D": 10.0
        }
      ],
      "score": 0.0,
      "ori_weight": 60.0,
      "weight": 0.43333333333333335
    },
    {
      "taski": 2,
      "task": "Integrity",
      "dics": [
        {
          "todo": 1,
          "question": "No output uncertainties are given",
          "O": 1.0,
          "S": 9.0,
          "D": 9.0
        }
      ],
      "score": 4.3267487109222245,
      "ori_weight": 0.0,
      "weight": 0.1
    },
    {
      "taski": 3,
      "task": "Explainability",
      "dics": [
        {
          "todo": 0,
          "question": "The model\u2019s decision-making process is not transparent",
          "O": 10.0,
          "S": 8.0,
          "D": 9.0
        }
      ],
      "score": 10.0,
      "ori_weight": 0.0,
      "weight": 0.1
    },
    {
      "taski": 4,
      "task": "Safety",
      "dics": [
        {
          "todo": 2,
          "question": "Erroneous decisions might lead to critical consequences",
          "O": 9.0,
          "S": 9.0,
          "D": 7.0
        }
      ],
      "score": 8.276772529143361,
      "ori_weight": 0.0,
      "weight": 0.1
    }
  ],
  "result": 0.0
}